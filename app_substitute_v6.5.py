import streamlit as st
import streamlit.components.v1 as components
import pdfplumber
import pandas as pd
import re
import json
from datetime import date, timedelta

# è¨­å®šé é¢è³‡è¨Š
st.set_page_config(page_title="æˆå¾·é«˜ä¸­ æ™ºæ…§èª¿ä»£èª²ç³»çµ± v7.0", layout="wide")

# ==========================================
# 1. å¼·åŠ›è³‡æ–™æ¸…æ´—å€ (é‡å° 114-2 èª²è¡¨å„ªåŒ–)
# ==========================================

def clean_cell_text_v7(text):
    """
    v7 è¶…ç´šæ¸…æ´—ï¼š
    1. ç§»é™¤äº‚ç¢¼ (å¦‚ Ú©Ù…)
    2. ç§»é™¤æ™‚é–“æ ¼å¼ (é¿å…èª¤åˆ¤ç‚ºèª²ç¨‹)
    3. ç§»é™¤æ’ç‰ˆé›œå­—
    """
    if not isinstance(text, str) or not text:
        return ""
    
    # ç§»é™¤ç‰¹å®šäº‚ç¢¼èˆ‡é›œè¨Š (é‡å°æ‚¨çš„ PDF ç‰‡æ®µ)
    text = re.sub(r'[Ú©Ù…]', '', text) 
    text = text.replace("ç§‘ç›®æ˜Ÿ", "").replace("æ™‚é–“ç­æœŸ", "").replace("æ™‚é–“", "").replace("ç­ç´š", "")
    
    # æ¸…é™¤æ™‚é–“æ ¼å¼ (ä¾‹å¦‚ 08:00, 9:00, 16:10) - é¿å…é€™äº›è¢«ç•¶æˆèª²ç¨‹åç¨±
    text = re.sub(r'\d{1,2}[:ï¼š]\d{2}', '', text)
    
    # æ¸…é™¤ã€Œç¬¬ X ç¯€ã€
    text = re.sub(r'ç¬¬\s*[0-9ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«]\s*ç¯€', '', text)
    
    # æ¸…é™¤å¸¸è¦‹ç„¡æ„ç¾©å­—è©
    noise_words = ["æ—©è‡ªç¿’", "åˆä¼‘", "ä¸Š", "ä¸‹", "åˆ", "èª²ç¨‹", "æ˜ŸæœŸ", "å°å¸«"]
    for w in noise_words:
        text = text.replace(w, "")
        
    # è™•ç†æ›è¡Œï¼šå°‡æ›è¡Œè½‰ç‚ºç©ºç™½ï¼Œä¸¦ç§»é™¤å¤šé¤˜ç©ºç™½
    # æ‚¨çš„ç‰‡æ®µé¡¯ç¤º "æ–‡\nåœ‹ä¸€3"ï¼Œé€™è£¡å°‡å…¶åˆä½µç‚º "æ–‡ åœ‹ä¸€3"
    text = text.replace("\n", " ").strip()
    
    return text

def extract_class_and_course(content_str):
    """
    åˆ†é›¢ç­ç´šèˆ‡èª²ç¨‹ (ä¾‹å¦‚ "æ–‡ åœ‹ä¸€3" -> ç­ç´š:åœ‹ä¸€3, èª²ç¨‹:æ–‡)
    """
    if not content_str: return "", ""
    
    # æŠ“å–ç­ç´š (é«˜/åœ‹ + ä¸€äºŒä¸‰ + æ•¸å­—)
    # å¢åŠ å° "åœ‹-3" é€™ç¨®æ ¼å¼çš„æ”¯æ´ (ç‰‡æ®µä¸­æœ‰å‡ºç¾)
    class_pattern = re.search(r'([é«˜åœ‹][ä¸€äºŒä¸‰\-]\s*\d+)', content_str)
    
    if class_pattern:
        raw_class = class_pattern.group(1)
        class_code = raw_class.replace(" ", "").replace("-", "") # çµ±ä¸€æ ¼å¼: åœ‹-3 -> åœ‹3
        
        # å°‡ç­ç´šç§»é™¤ï¼Œå‰©ä¸‹çš„å°±æ˜¯èª²ç¨‹
        course_name = content_str.replace(raw_class, "").strip()
        course_name = course_name.replace("_", " ").strip() # ç§»é™¤åº•ç·š
        return class_code, course_name
    else:
        return "", content_str

@st.cache_data
def get_teacher_list(df):
    return sorted(df['teacher'].unique())

# ==========================================
# 2. PDF è§£ææ ¸å¿ƒ (v7 é›™é‡å¼•æ“)
# ==========================================

def extract_tables_with_fallback(page):
    """
    æ™ºæ…§é‡è©¦æ©Ÿåˆ¶ï¼š
    1. å…ˆå˜—è©¦é è¨­è§£æ (ä¾è³´æ ¼ç·š)
    2. å¦‚æœæ¬„ä½éå°‘ (å¯èƒ½æ ¼ç·šæ¶ˆå¤±å°è‡´é»æ¬„)ï¼Œæ”¹ç”¨ 'text' ç­–ç•¥ (ä¾è³´æ–‡å­—é–“éš™)
    """
    # ç­–ç•¥ A: é è¨­ (lines)
    tables = page.extract_tables()
    
    # æª¢æŸ¥ç­–ç•¥ A çš„å“è³ª
    is_bad = False
    if not tables:
        is_bad = True
    else:
        # æª¢æŸ¥ç¬¬ä¸€å¼µè¡¨ï¼Œå¦‚æœæ¬„ä½æ•¸å°‘æ–¼ 5 (æ­£å¸¸é€±èª²è¡¨è‡³å°‘è¦æœ‰ 1æ¬„æ™‚é–“ + 5æ¬„æ˜ŸæœŸ = 6æ¬„)
        # æ‚¨çš„ç‰‡æ®µé¡¯ç¤º "äºŒä¸‰" é»åœ¨ä¸€èµ·ï¼Œé€™æœƒå°è‡´æ¬„ä½æ•¸è®Šå°‘
        max_cols = max([len(row) for row in tables[0] if row])
        if max_cols < 6: 
            is_bad = True
            
    if is_bad:
        # ç­–ç•¥ B: å¼·åˆ¶ä½¿ç”¨æ–‡å­—é–“éš™ (text strategy)
        # é€™èƒ½è§£æ±º "äºŒä¸‰" é»åœ¨ä¸€èµ·çš„å•é¡Œ
        tables = page.extract_tables(table_settings={
            "vertical_strategy": "text", 
            "horizontal_strategy": "text",
            "snap_tolerance": 5,
        })
        
    return tables

@st.cache_data
def parse_pdf_v7(uploaded_file):
    extracted_data = []
    teacher_classes_map = {} 
    
    # æ™‚é–“é—œéµå­— (ç”¨æ–¼å®šä½åˆ—)
    time_keywords = {
        "1": ["ç¬¬ä¸€ç¯€", "08:00", "8:00"], "2": ["ç¬¬äºŒç¯€", "09:00", "9:00"],
        "3": ["ç¬¬ä¸‰ç¯€", "10:00"], "4": ["ç¬¬å››ç¯€", "11:00"],
        "5": ["ç¬¬äº”ç¯€", "13:00"], "6": ["ç¬¬å…­ç¯€", "14:00"],
        "7": ["ç¬¬ä¸ƒç¯€", "15:00"], "8": ["ç¬¬å…«ç¯€", "16:00"]
    }
    
    day_map_template = {"ä¸€": "ä¸€", "äºŒ": "äºŒ", "ä¸‰": "ä¸‰", "å››": "å››", "äº”": "äº”"}

    with pdfplumber.open(uploaded_file) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text() or ""
            
            # æŠ“å–æ•™å¸«å§“å
            teacher_name = f"Teacher_{i}"
            match = re.search(r"æ•™å¸«[:ï¼š\s]+(\S+)", text)
            if match:
                raw_name = match.group(1).strip()
                # æ’é™¤ "103å°å¸«" é€™ç¨®å¾Œç¶´ï¼Œåªå–åå­— (ä¾‹å¦‚ "é™³æ…§æ•")
                # å‡è¨­åå­—é€šå¸¸æ˜¯ 2-4 å€‹å­—
                if len(raw_name) > 4 and "å°å¸«" in raw_name:
                     raw_name = raw_name.replace("å°å¸«", "")
                     # å–å‰å¹¾å€‹å­—ç•¶åå­—ï¼Œå‰©ä¸‹çš„å¯èƒ½æ˜¯ç­ç´š
                     teacher_name = raw_name[:3] 
                else:
                    teacher_name = raw_name
            
            if teacher_name not in teacher_classes_map:
                teacher_classes_map[teacher_name] = set()

            # ä½¿ç”¨é›™é‡å¼•æ“æå–è¡¨æ ¼
            tables = extract_tables_with_fallback(page)
            
            if not tables: continue
            raw_table = tables[0] # å–ç¬¬ä¸€å¼µè¡¨
            
            col_map = {} 
            row_map = {} 

            # --- æ­¥é©Ÿ A: å‹•æ…‹å®šä½æ˜ŸæœŸæ¬„ä½ (Header Scout) ---
            # æƒæå‰ 5 åˆ—ï¼Œå°‹æ‰¾ "ä¸€", "äºŒ", "ä¸‰"...
            found_header = False
            for r_idx, row in enumerate(raw_table[:6]):
                for c_idx, cell in enumerate(row):
                    if not cell: continue
                    cell_str = str(cell).replace("\n", "").strip()
                    
                    # æª¢æŸ¥é€™ä¸€æ ¼æ˜¯å¦æœ‰æ˜ŸæœŸé—œéµå­—
                    for k, v in day_map_template.items():
                        if k in cell_str:
                            col_map[c_idx] = v
                            found_header = True
                if found_header and len(col_map) >= 3: # è‡³å°‘æ‰¾åˆ°ä¸‰å¤©å°±å¯ä»¥ç•¶ä½œæ¨™é¡Œåˆ—äº†
                    break
            
            # å¦‚æœå®Œå…¨æ‰¾ä¸åˆ°æ¨™é¡Œ (Fallback)ï¼Œå‡è¨­æ¨™æº–çµæ§‹
            if not col_map:
                # å‡è¨­ Col 0=Time, Col 1=ä¸€, Col 2=äºŒ ...
                # æ ¹æ“šæ‚¨çš„ç‰‡æ®µï¼Œå¦‚æœæœ‰åç§»ï¼Œé€™è£¡å¯èƒ½éœ€è¦èª¿æ•´ï¼Œä½† Strategy B é€šå¸¸æœƒè®“å®ƒå›æ­¸æ¨™æº–
                col_map = {1: "ä¸€", 2: "äºŒ", 3: "ä¸‰", 4: "å››", 5: "äº”"}

            # --- æ­¥é©Ÿ B: å®šä½ç¯€æ¬¡åˆ— ---
            for r_idx, row in enumerate(raw_table):
                # æŠŠæ•´åˆ—æ–‡å­—æ¥èµ·ä¾†æª¢æŸ¥
                row_text = "".join([str(c) for c in row if c]).replace(" ", "").replace("\n", "")
                for p_key, kws in time_keywords.items():
                    for kw in kws:
                        if kw in row_text:
                            row_map[r_idx] = p_key
                            break
            
            # --- æ­¥é©Ÿ C: æå–è³‡æ–™ ---
            for r_idx, period in row_map.items():
                for c_idx, day in col_map.items():
                    if c_idx < len(raw_table[r_idx]):
                        raw_cell = str(raw_table[r_idx][c_idx])
                        
                        # æ¸…æ´—å…§å®¹
                        clean_content = clean_cell_text_v7(raw_cell)
                        is_free = (len(clean_content) < 1) # æ¸…æ´—å¾Œç‚ºç©ºå­—ä¸²å³ç‚ºç©ºå ‚
                        
                        extracted_data.append({
                            "teacher": teacher_name, "day": day, "period": period,
                            "content": clean_content, "is_free": is_free
                        })
                        
                        cls, _ = extract_class_and_course(clean_content)
                        if cls: teacher_classes_map[teacher_name].add(cls)

            # è£œç§‘ç›®é‚è¼¯
            subject = "ç¶œåˆ"
            all_content = " ".join([d['content'] for d in extracted_data if d['teacher'] == teacher_name])
            subject_keywords = {
                "åœ‹èªæ–‡": "åœ‹æ–‡", "è‹±æ–‡": "è‹±æ–‡", "æ•¸å­¸": "æ•¸å­¸", "ç‰©ç†": "è‡ªç„¶", "åŒ–å­¸": "è‡ªç„¶", 
                "ç”Ÿç‰©": "è‡ªç„¶", "åœ°ç§‘": "è‡ªç„¶", "æ­·å²": "ç¤¾æœƒ", "åœ°ç†": "ç¤¾æœƒ", "å…¬æ°‘": "ç¤¾æœƒ",
                "é«”è‚²": "å¥é«”", "ç¾è¡“": "è—èƒ½", "éŸ³æ¨‚": "è—èƒ½", "è³‡è¨Š": "ç§‘æŠ€", "ç”Ÿç§‘": "ç§‘æŠ€",
                "å…¨æ°‘åœ‹é˜²": "åœ‹é˜²", "è­·ç†": "å¥é«”", "èªæ–‡": "åœ‹æ–‡"
            }
            detected_counts = {}
            for k, v in subject_keywords.items():
                if k in all_content: detected_counts[v] = detected_counts.get(v, 0) + 1
            if detected_counts: subject = max(detected_counts, key=detected_counts.get)
            
            for item in extracted_data:
                if item['teacher'] == teacher_name: item['subject'] = subject
                
    return extracted_data, teacher_classes_map

# ==========================================
# 3. ä»‹é¢èˆ‡åŠŸèƒ½ (ç¶­æŒ v6.5 çš„å®Œæ•´åŠŸèƒ½)
# ==========================================

@st.dialog("èª¿èª²è©³ç´°è³‡è¨Š", width="large")
def show_schedule_popup(target_teacher, full_df, initiator_name, source_details, target_details):
    
    st.subheader("ğŸ“† è¨­å®šèª¿èª²æ—¥æœŸ")
    c1, c2 = st.columns(2)
    with c1:
        default_date_a = date.today() + timedelta(days=1)
        date_a = st.date_input(f"Aè€å¸« ({initiator_name}) èª¿èª²æ—¥æœŸ", value=default_date_a)
        str_date_a = date_a.strftime("%Y/%m/%d")
    with c2:
        default_date_b = date.today() + timedelta(days=2)
        date_b = st.date_input(f"Bè€å¸« ({target_teacher}) èª¿èª²æ—¥æœŸ", value=default_date_b)
        str_date_b = date_b.strftime("%Y/%m/%d")

    st.divider()

    st.subheader(f"ğŸ“… {target_teacher} è€å¸«çš„é€±èª²è¡¨")
    t_df = full_df[full_df['teacher'] == target_teacher]
    
    if not t_df.empty:
        pivot_df = t_df.pivot(index='period', columns='day', values='content')
        pivot_df = pivot_df.reindex([str(i) for i in range(1, 9)])
        pivot_df = pivot_df.reindex(columns=["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”"])

        def highlight_target(val, row_idx, col_name):
            if row_idx == target_details['period'] and col_name == target_details['day']:
                return 'background-color: #ffcccc; color: #8b0000; font-weight: bold; border: 2px solid red;'
            return ''

        styled_df = pivot_df.style.apply(lambda x: pd.DataFrame(
            [[highlight_target(x.iloc[i, j], pivot_df.index[i], pivot_df.columns[j]) 
              for j in range(len(pivot_df.columns))] 
             for i in range(len(pivot_df.index))],
            index=pivot_df.index, columns=pivot_df.columns
        ), axis=None)

        st.dataframe(styled_df, use_container_width=True)
        st.caption("ğŸŸ¥ ç´…è‰²æ¨™è¨˜ç‚ºæ‚¨é¸å®šè¦äº¤æ›çš„æ™‚æ®µ")
    
    st.divider()

    st.subheader("âœ‰ï¸ èª¿èª²é‚€è«‹é€šçŸ¥å–®")
    
    source_str = f"{str_date_a} (é€±{source_details['day']}) ç¬¬{source_details['period']}ç¯€ {source_details['class']} {source_details['course']}"
    target_str = f"{str_date_b} (é€±{target_details['day']}) ç¬¬{target_details['period']}ç¯€ {target_details['class']} {target_details['course']}"

    msg_template = f"""{target_teacher} è€å¸«æ‚¨å¥½ï¼š

æˆ‘æ˜¯ {initiator_name}ã€‚
