import streamlit as st
import pdfplumber
import pandas as pd
import re
import io

# ==========================================
# ç³»çµ±è¨­å®š
# ==========================================
st.set_page_config(page_title="æˆå¾·é«˜ä¸­ æ™ºæ…§èª¿ä»£èª²ç³»çµ± v14", layout="wide")

# ==========================================
# 1. æ ¸å¿ƒè§£æé‚è¼¯ (é‡å° 114-2 PDF å„ªåŒ–)
# ==========================================

def clean_text(text):
    """
    æ¸…æ´—æ–‡å­—ï¼šç§»é™¤ PDF å¸¸è¦‹çš„é›œè¨Šèˆ‡éš±è—å­—å…ƒ
    """
    if not text: return ""
    # ç§»é™¤æ³¢æ–¯/é˜¿æ‹‰ä¼¯èªç³»äº‚ç¢¼ (é‡å°æ‚¨çš„æª”æ¡ˆå‡ºç¾çš„ Ú©Ù…, Ú©Ø±)
    text = re.sub(r'[\u0600-\u06FF]', '', text)
    # ç§»é™¤é›¶å¯¬åº¦ç©ºæ ¼ç­‰éš±å½¢å­—å…ƒ
    text = re.sub(r'[\u200b-\u200f\ufeff]', '', text)
    # ç§»é™¤å¤šé¤˜ç©ºç™½
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def get_teacher_name(page):
    """
    ç²¾æº–æå–æ•™å¸«å§“å
    é‚è¼¯ï¼šå°‹æ‰¾ 'æ•™å¸«:' é—œéµå­—ï¼Œä¸¦åªæŠ“å–å…¶å¾Œçš„ä¸­æ–‡å§“åï¼Œé¿é–‹è·ç¨±èˆ‡æ•¸å­—
    """
    # åªæƒæé é¢ä¸Šæ–¹ 20% çš„å€åŸŸï¼Œé¿å…è®€åˆ°ä¸‹é¢çš„èª²è¡¨å…§å®¹
    top_area = page.crop((0, 0, page.width, page.height * 0.2))
    text = top_area.extract_text()
    
    if not text: return "æœªçŸ¥æ•™å¸«"

    # ç­–ç•¥ A: æ­£å‰‡è¡¨é”å¼æŠ“å– "æ•™å¸«:é™³å¤§æ–‡" æ ¼å¼
    # è§£é‡‹ï¼šå°‹æ‰¾ "æ•™å¸«" -> å¯æœ‰å¯ç„¡çš„å†’è™Ÿæˆ–ç©ºç™½ -> æŠ“å–é€£çºŒçš„ä¸­æ–‡å­—
    match = re.search(r'æ•™å¸«[:ï¼š\s]*([\u4e00-\u9fa5]+)', text)
    if match:
        name = match.group(1)
        # å†æ¬¡ç¢ºèªç§»é™¤å¸¸è¦‹è·ç¨±
        for title in ["å°å¸«", "å°ˆä»»", "ä»£ç†", "æ•™å®˜", "çµ„é•·", "ä¸»ä»»"]:
            name = name.replace(title, "")
        return name

    # ç­–ç•¥ B: å¦‚æœæ‰¾ä¸åˆ° "æ•™å¸«:"ï¼Œå˜—è©¦æ‰¾æ¨™é¡Œè¡Œç‰¹å¾µ (é€šå¸¸å­—é«”è¼ƒå¤§ï¼Œä½†é€™è£¡ç°¡åŒ–ç‚ºæ’é™¤æ³•)
    lines = text.split('\n')
    for line in lines:
        clean_line = clean_text(line)
        # å¦‚æœé€™ä¸€è¡Œåªæœ‰ 2-4 å€‹ä¸­æ–‡å­—ï¼Œä¸”ä¸æ˜¯å¸¸è¦‹æ¨™é¡Œ
        if 2 <= len(clean_line) <= 4 and re.match(r'^[\u4e00-\u9fa5]+$', clean_line):
            if "èª²è¡¨" not in clean_line and "é«˜ä¸­" not in clean_line:
                return clean_line
                
    return "æœªçŸ¥æ•™å¸«"

def get_virtual_grid(page):
    """
    å»ºç«‹è™›æ“¬ç¶²æ ¼ (GPS å®šä½æ³•)
    ä¸ä¾è³´è¡¨æ ¼ç·šæ¢ï¼Œè€Œæ˜¯æ ¹æ“šæ–‡å­—åº§æ¨™ä¾†åˆ¤æ–·æ¬„ä½
    """
    words = page.extract_words(keep_blank_chars=True)
    width = page.width
    height = page.height

    # 1. å®šä½ X è»¸ (æ˜ŸæœŸ)
    # é è¨­é‚è¼¯ï¼šèª²è¡¨é€šå¸¸å·¦é‚Š 15% æ˜¯ç¯€æ¬¡ï¼Œå³é‚Š 85% å‡åˆ†çµ¦é€±ä¸€~é€±äº”
    # å¦‚æœèƒ½æŠ“åˆ° "ä¸€", "äºŒ"... çš„åº§æ¨™å°±ä¿®æ­£ï¼ŒæŠ“ä¸åˆ°å°±ç”¨é è¨­å€¼
    
    day_cols = []
    # å˜—è©¦å°‹æ‰¾æ˜ŸæœŸå¹¾çš„æ¨™é¡Œåº§æ¨™
    day_headers = {"ä¸€": None, "äºŒ": None, "ä¸‰": None, "å››": None, "äº”": None}
    for w in words:
        if w['top'] < height * 0.2: # åªçœ‹ä¸Šæ–¹
            txt = w['text'].strip()
            for d in day_headers.keys():
                if d in txt and day_headers[d] is None:
                    day_headers[d] = (w['x0'], w['x1'])

    # åˆ¤æ–·æ˜¯å¦æˆåŠŸæŠ“åˆ°å¤§éƒ¨åˆ†æ˜ŸæœŸ
    found_days = [d for d in day_headers.values() if d is not None]
    
    if len(found_days) >= 3:
        # å¦‚æœæŠ“å¾—åˆ°åº§æ¨™ï¼Œå°±ç”¨åº§æ¨™ä¸­é–“é»ä¾†åˆ‡åˆ†
        sorted_days = sorted([k for k, v in day_headers.items() if v], key=lambda k: day_headers[k][0])
        # é€™è£¡ç°¡åŒ–é‚è¼¯ï¼šç›´æ¥ç”¨æ¨™é¡Œçš„ä¸­å¿ƒé»æ“´æ•£
        # æ›´å¥½çš„åšæ³•æ˜¯ï¼šè¨ˆç®—æ¬„ä½é‚Šç•Œ
        # é€™è£¡æ¡ç”¨ã€Œç›²çŒœè£œæ­£æ³•ã€ï¼šå¦‚æœ PDF å¾ˆäº‚ï¼Œç›´æ¥ç”¨å¹¾ä½•å¹³å‡åˆ†å‰²é€šå¸¸æœ€ç©©
        start_x = width * 0.12 # ç•¥éå·¦å´ç¯€æ¬¡æ¬„
        col_width = (width - start_x) / 5
        for i, d in enumerate(["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”"]):
            day_cols.append({
                "day": d,
                "x0": start_x + i * col_width,
                "x1": start_x + (i + 1) * col_width
            })
    else:
        # å®Œå…¨æŠ“ä¸åˆ°æ¨™é¡Œ (äº‚ç¢¼åš´é‡)ï¼Œç›´æ¥ä½¿ç”¨å¹¾ä½•åˆ†å‰²
        start_x = width * 0.12
        col_width = (width - start_x) / 5
        for i, d in enumerate(["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”"]):
            day_cols.append({
                "day": d,
                "x0": start_x + i * col_width,
                "x1": start_x + (i + 1) * col_width
            })

    # 2. å®šä½ Y è»¸ (ç¯€æ¬¡)
    # æƒæå·¦å´æ¬„ä½ (x < width*0.15) çš„æ–‡å­—ï¼Œå°‹æ‰¾ "08:", "09:", "1" ç­‰ç‰¹å¾µ
    row_starts = {} # è¨˜éŒ„æ¯ä¸€ç¯€çš„é–‹å§‹ Y åº§æ¨™
    
    # å®šç¾©ç¯€æ¬¡é—œéµå­—
    period_kws = {
        "1": ["08:", "8:", "ç¬¬ä¸€ç¯€"], "2": ["09:", "9:", "ç¬¬äºŒç¯€"],
        "3": ["10:", "10", "ç¬¬ä¸‰ç¯€"], "4": ["11:", "11", "ç¬¬å››ç¯€"],
        "5": ["13:", "12:", "ç¬¬äº”ç¯€"], "6": ["14:", "14", "ç¬¬å…­ç¯€"],
        "7": ["15:", "15", "ç¬¬ä¸ƒç¯€"], "8": ["16:", "16", "ç¬¬å…«ç¯€"]
    }
    
    for w in words:
        if w['x0'] > width * 0.2: continue # åªçœ‹å·¦å´
        txt = w['text'].replace(" ", "")
        for p, kws in period_kws.items():
            if p not in row_starts:
                for kw in kws:
                    if kw in txt:
                        row_starts[p] = w['top']
                        break
    
    rows = []
    # å¦‚æœæœ‰æŠ“åˆ°ç¯€æ¬¡ï¼Œå°±ç”¨æŠ“åˆ°çš„ï¼›æ²’æŠ“åˆ°å°±ç”¨å…§æ’æ³•
    # ç‚ºäº†ç¨‹å¼å¼·å¥æ€§ï¼Œé€™è£¡æ¡ç”¨ã€Œå›ºå®šé«˜åº¦æ¨ç®—æ³•ã€ä½œç‚ºå‚™æ¡ˆ
    # å‡è¨­ç¬¬ä¸€ç¯€å¾ y=150 é–‹å§‹ (å¤§æ¦‚å€¼)ï¼Œæ¯ç¯€é«˜åº¦ç´„ 50-60
    base_y = 100
    if "1" in row_starts: base_y = row_starts["1"]
    
    # ä¼°ç®—å¹³å‡è¡Œé«˜
    step = 55 # é è¨­ç¶“é©—å€¼
    if "8" in row_starts and "1" in row_starts:
        step = (row_starts["8"] - row_starts["1"]) / 7
    
    for i in range(1, 9):
        p = str(i)
        top = row_starts.get(p, base_y + (i-1)*step)
        # å®šç¾©é€™ä¸€ç¯€çš„ä¸Šä¸‹ç¯„åœ (ç¨å¾®å¯¬ä¸€é»ä»¥å…æ¼å­—)
        rows.append({"period": p, "top": top - 5, "bottom": top + step + 5})

    return day_cols, rows, words

def extract_class_and_course(content_str):
    """åˆ†é›¢ç­ç´šèˆ‡èª²ç¨‹ (ä¾‹å¦‚: 'åœ‹ä¸€1 åœ‹æ–‡')"""
    if not content_str: return "", ""
    # æŠ“å–ç­ç´š (é«˜/åœ‹ + ä¸€äºŒä¸‰/- + æ•¸å­—)
    class_pattern = re.search(r'([é«˜åœ‹][ä¸€äºŒä¸‰\-]\s*\d+)', content_str)
    if class_pattern:
        raw_class = class_pattern.group(1)
        class_code = raw_class.replace(" ", "").replace("-", "")
        course_name = content_str.replace(raw_class, "").strip()
        return class_code, course_name
    return "", content_str

def parse_pdf_v14(uploaded_file):
    extracted_data = []
    
    with pdfplumber.open(uploaded_file) as pdf:
        for i, page in enumerate(pdf.pages):
            # 1. æŠ“è€å¸«åå­—
            teacher_name = get_teacher_name(page)
            
            # å¦‚æœé‚„æ˜¯æŠ“éŒ¯ (ä¾‹å¦‚æŠ“åˆ° 'æˆå¾·é«˜ä¸­')ï¼Œå¼·åˆ¶éæ¿¾
            if "æˆå¾·" in teacher_name or "èª²è¡¨" in teacher_name:
                teacher_name = f"æ•™å¸«_{i+1}"

            # 2. å–å¾—ç¶²æ ¼èˆ‡æ–‡å­—
            day_cols, rows, all_words = get_virtual_grid(page)

            # 3. å°‡æ–‡å­—æŠ•å…¥ç¶²æ ¼ (Bucket Sorting)
            # ä½¿ç”¨å­—å…¸ä¾†æ”¶é›†æ¯å€‹æ ¼å­è£¡çš„æ–‡å­—
            grid_content = {} # Key: "Mon_1", Value: ["åœ‹æ–‡", "åœ‹ä¸€1"]

            for w in all_words:
                # è¨ˆç®—æ–‡å­—ä¸­å¿ƒé»
                cx = (w['x0'] + w['x1']) / 2
                cy = (w['top'] + w['bottom']) / 2
                
                # åˆ¤æ–·å±¬æ–¼å“ªä¸€å¤© (Xè»¸)
                matched_day = None
                for col in day_cols:
                    if col['x0'] <= cx <= col['x1']:
                        matched_day = col['day']
                        break
                
                # åˆ¤æ–·å±¬æ–¼å“ªä¸€ç¯€ (Yè»¸)
                matched_period = None
                for row in rows:
                    if row['top'] <= cy <= row['bottom']:
                        matched_period = row['period']
                        break
                
                if matched_day and matched_period:
                    key = f"{matched_day}_{matched_period}"
                    if key not in grid_content: grid_content[key] = []
                    grid_content[key].append(w['text'])

            # 4. æ•´ç†çµæœ
            for d_col in day_cols:
                d = d_col['day']
                for r_row in rows:
                    p = r_row['period']
                    key = f"{d}_{p}"
                    
                    raw_texts = grid_content.get(key, [])
                    full_text = " ".join(raw_texts)
                    clean_content = clean_text(full_text)
                    
                    # éæ¿¾æ‰å¯èƒ½æ˜¯ header æ®˜ç•™çš„é›œè¨Š (ä¾‹å¦‚ "ä¸€", "æ—©è‡ªç¿’")
                    if clean_content in ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "æ—©è‡ªç¿’", "åˆä¼‘"]:
                        clean_content = ""
                    
                    is_free = (len(clean_content) < 1)
                    
                    extracted_data.append({
                        "teacher": teacher_name,
                        "day": d,
                        "period": p,
                        "content": clean_content,
                        "is_free": is_free
                    })

    # è½‰æˆ DataFrame
    df = pd.DataFrame(extracted_data)
    
    # è‡ªå‹•è£œç§‘ç›® (æ ¹æ“šæ¯å€‹è€å¸«çš„èª²ç¨‹å…§å®¹æŠ•ç¥¨æ±ºå®šç§‘ç›®)
    if not df.empty:
        for teacher in df['teacher'].unique():
            t_data = df[df['teacher'] == teacher]
            all_content = " ".join(t_data['content'])
            
            # é—œéµå­—åˆ¤å®š
            subject = "ç¶œåˆ"
            keywords = {
                "åœ‹èªæ–‡":"åœ‹æ–‡", "åœ‹æ–‡":"åœ‹æ–‡", "è‹±æ–‡":"è‹±æ–‡", "è‹±èª":"è‹±æ–‡", 
                "æ•¸å­¸":"æ•¸å­¸", "ç‰©ç†":"è‡ªç„¶", "åŒ–å­¸":"è‡ªç„¶", "ç”Ÿç‰©":"è‡ªç„¶", "åœ°ç§‘":"è‡ªç„¶",
                "æ­·å²":"ç¤¾æœƒ", "åœ°ç†":"ç¤¾æœƒ", "å…¬æ°‘":"ç¤¾æœƒ", "ç¤¾æœƒ":"ç¤¾æœƒ",
                "é«”è‚²":"å¥é«”", "ç¾è¡“":"è—èƒ½", "éŸ³æ¨‚":"è—èƒ½", "ç”Ÿæ´»ç§‘æŠ€":"ç§‘æŠ€", "è³‡è¨Š":"ç§‘æŠ€",
                "åœ‹é˜²":"åœ‹é˜²", "å¥åº·":"å¥é«”"
            }
            detected = {}
            for k, v in keywords.items():
                if k in all_content: detected[v] = detected.get(v, 0) + 1
            
            if detected: subject = max(detected, key=detected.get)
            
            # å›å¡«
            df.loc[df['teacher'] == teacher, 'subject'] = subject
            
    return df

# ==========================================
# 2. UI ä»‹é¢
# ==========================================

def main():
    st.title("ğŸ« æˆå¾·é«˜ä¸­ æ™ºæ…§èª¿ä»£èª²ç³»çµ± v14")
    st.caption("âœ… ä¿®æ­£ç‰ˆï¼šé‡å° 114-2 èª²è¡¨äº‚ç¢¼å•é¡Œé€²è¡Œå°ˆå±¬å„ªåŒ–")

    st.markdown("### æ­¥é©Ÿ 1ï¼šä¸Šå‚³èª²è¡¨ PDF")
    uploaded_file = st.file_uploader("è«‹é¸æ“‡ PDF æª”æ¡ˆ", type=["pdf"])

    if uploaded_file:
        with st.spinner("æ­£åœ¨é€²è¡Œ GPS åº§æ¨™å®šä½åˆ†æèˆ‡äº‚ç¢¼æ¸…æ´—..."):
            try:
                df = parse_pdf_v14(uploaded_file)
                
                # æª¢æŸ¥æ˜¯å¦æˆåŠŸæŠ“åˆ°è€å¸«
                teachers = sorted(df['teacher'].unique())
                if len(teachers) == 0:
                    st.error("è§£æå¤±æ•—ï¼šæ‰¾ä¸åˆ°ä»»ä½•æ•™å¸«è³‡æ–™ã€‚è«‹ç¢ºèª PDF æ ¼å¼ã€‚")
                else:
                    st.success(f"ğŸ‰ è§£ææˆåŠŸï¼å…±æ‰¾åˆ° {len(teachers)} ä½æ•™å¸«ã€‚")
                    
                    # é¡¯ç¤ºè³‡æ–™é è¦½ (é™¤éŒ¯ç”¨)
                    with st.expander("æŸ¥çœ‹åŸå§‹è³‡æ–™é è¦½"):
                        st.dataframe(df.head(10))

                    # --- åŠŸèƒ½å€ ---
                    tab1, tab2, tab3 = st.tabs(["ğŸ“… èª²è¡¨æŸ¥è©¢", "ğŸš‘ ç©ºå ‚ä»£èª²", "ğŸ”„ èª¿èª²äº’æ›"])

                    # Tab 1: æŸ¥è©¢
                    with tab1:
                        t_select = st.selectbox("é¸æ“‡æ•™å¸«", teachers)
                        if t_select:
                            t_df = df[df['teacher'] == t_select]
                            # è½‰æˆé€±èª²è¡¨æ ¼å¼
                            pivot = t_df.pivot(index='period', columns='day', values='content')
                            # æ’åº
                            pivot = pivot.reindex([str(i) for i in range(1,9)]).reindex(columns=["ä¸€","äºŒ","ä¸‰","å››","äº”"])
                            st.dataframe(pivot, use_container_width=True)

                    # Tab 2: ä»£èª²
                    with tab2:
                        c1, c2 = st.columns(2)
                        q_day = c1.selectbox("ç¼ºèª²æ˜ŸæœŸ", ["ä¸€","äºŒ","ä¸‰","å››","äº”"])
                        q_per = c2.selectbox("ç¼ºèª²ç¯€æ¬¡", [str(i) for i in range(1,9)])
                        
                        frees = df[(df['day']==q_day) & (df['period']==q_per) & (df['is_free']==True)]
                        if not frees.empty:
                            st.write(f"ä»¥ä¸‹è€å¸«åœ¨ **é€±{q_day} ç¬¬{q_per}ç¯€** ç‚ºç©ºå ‚ï¼š")
                            st.dataframe(frees[['teacher', 'subject']], hide_index=True)
                        else:
                            st.warning("è©²æ™‚æ®µç„¡äººç©ºå ‚ã€‚")

                    # Tab 3: èª¿èª²
                    with tab3:
                        c1, c2, c3 = st.columns([2,1,1])
                        init = c1.selectbox("ç™¼èµ·æ•™å¸« (A)", teachers)
                        sd = c2.selectbox("A æ¬²èª¿å‡ºæ˜ŸæœŸ", ["ä¸€","äºŒ","ä¸‰","å››","äº”"])
                        sp = c3.selectbox("A æ¬²èª¿å‡ºç¯€æ¬¡", [str(i) for i in range(1,9)])
                        
                        target = st.selectbox("æŒ‡å®šå°è±¡ (B)", ["ä¸æŒ‡å®š"] + [t for t in teachers if t != init])
                        
                        if st.button("æœå°‹äº¤æ›æ–¹æ¡ˆ"):
                            # å°‹æ‰¾é‚è¼¯ï¼š
                            # 1. æ‰¾å‡º A åœ¨è©²æ™‚æ®µçš„èª² (Source)
                            # 2. æ‰¾å‡º B åœ¨è©²æ™‚æ®µæ˜¯ç©ºå ‚ (Target Free)
                            # 3. æ‰¾å‡º B æœ‰èª²çš„æ™‚æ®µï¼Œä¸”è©²æ™‚æ®µ A æ˜¯ç©ºå ‚ (Swap Opportunity)
                            
                            cands = df[(df['day']==sd) & (df['period']==sp) & (df['is_free']==True) & (df['teacher']!=init)]
                            if target != "ä¸æŒ‡å®š":
                                cands = cands[cands['teacher'] == target]
                            
                            a_free_slots = set(df[(df['teacher']==init) & (df['is_free']==True)]['day'] + df[(df['teacher']==init) & (df['is_free']==True)]['period'])
                            
                            results = []
                            for b_name in cands['teacher'].unique():
                                b_courses = df[(df['teacher']==b_name) & (df['is_free']==False)]
                                for _, row in b_courses.iterrows():
                                    if (row['day'] + row['period']) in a_free_slots:
                                        results.append({
                                            "å°è±¡æ•™å¸«": b_name,
                                            "å¯äº¤æ›èª²ç¨‹": row['content'],
                                            "äº¤æ›è‡³æ˜ŸæœŸ": row['day'],
                                            "äº¤æ›è‡³ç¯€æ¬¡": row['period']
                                        })
                            
                            if results:
                                st.success(f"æ‰¾åˆ° {len(results)} å€‹äº¤æ›æ–¹æ¡ˆ")
                                st.dataframe(pd.DataFrame(results))
                            else:
                                st.warning("æ‰¾ä¸åˆ°ç¬¦åˆé›™æ–¹ç©ºå ‚æ¢ä»¶çš„äº¤æ›æ–¹æ¡ˆã€‚")

            except Exception as e:
                st.error(f"è§£æç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                st.info("å»ºè­°ï¼šå¦‚æœåªæœ‰å°‘æ•¸è€å¸«è§£æå¤±æ•—ï¼Œå¯èƒ½æ˜¯ PDF è©²é é¢æ ¼å¼ç‰¹æ®Šã€‚")

if __name__ == "__main__":
    main()
